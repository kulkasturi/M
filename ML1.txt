
pip install geopy


# In[2]:


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Step 1: Load and inspect the dataset
url = "https://www.kaggle.com/datasets/yasserh/uber-fares-dataset"
df = pd.read_csv(r"C:\Users\HP\Downloads\uber (1).csv")  # Update with your dataset path
print("First 5 rows of the dataset:\n", df.head())
print("\nDataset Info:\n")
df.info()

# Step 2: Pre-processing the dataset
# Dropping rows with missing values
df.dropna(inplace=True)

# Convert 'pickup_datetime' to datetime format
df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], errors='coerce')

# Extracting useful features from 'pickup_datetime'
df['hour'] = df['pickup_datetime'].dt.hour
df['day'] = df['pickup_datetime'].dt.day
df['month'] = df['pickup_datetime'].dt.month
df['year'] = df['pickup_datetime'].dt.year

# Remove rows with invalid latitude and longitude values
df = df[(df['pickup_latitude'].between(-90, 90)) & 
        (df['pickup_longitude'].between(-180, 180)) &
        (df['dropoff_latitude'].between(-90, 90)) & 
        (df['dropoff_longitude'].between(-180, 180))]


from geopy.distance import geodesic

# Calculate distance using geopy for each row
df['distance'] = df.apply(lambda row: geodesic((row['pickup_latitude'], row['pickup_longitude']), 
                                               (row['dropoff_latitude'], row['dropoff_longitude'])).km, axis=1)

# Remove rows with zero or missing distance
df = df[df['distance'] > 0]

# Step 3: Identifying outliers using IQR
Q1 = df['fare_amount'].quantile(0.25)
Q3 = df['fare_amount'].quantile(0.75)
IQR = Q3 - Q1
df = df[(df['fare_amount'] >= (Q1 - 1.5 * IQR)) & (df['fare_amount'] <= (Q3 + 1.5 * IQR))]

# Ensure all necessary columns are numeric for the correlation calculation
numeric_df = df.select_dtypes(include=[np.number])

# Step 4: Correlation analysis
plt.figure(figsize=(10, 6))
sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

# Step 5: Preparing data for modeling
features = ['distance', 'hour', 'day', 'month', 'year']
X = df[features]
y = df['fare_amount']

# Splitting data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Implementing Linear Regression
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)
y_pred_lr = lin_reg.predict(X_test)

# Step 7: Implementing Random Forest Regression
rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reg.fit(X_train, y_train)
y_pred_rf = rf_reg.predict(X_test)

# Step 8: Evaluating models
def evaluate_model(y_true, y_pred, model_name):
    print(f"\n{model_name} Performance:")
    print(f"RÂ² Score: {r2_score(y_true, y_pred):.2f}")
    print(f"RMSE: {np.sqrt(mean_squared_error(y_true, y_pred)):.2f}")

evaluate_model(y_test, y_pred_lr, "Linear Regression")
evaluate_model(y_test, y_pred_rf, "Random Forest Regression")

# Step 9: Plotting the best fit line for Linear Regression
plt.figure(figsize=(8, 5))
plt.scatter(X_test['distance'], y_test, color='blue', label='Actual Fares')
plt.plot(X_test['distance'], y_pred_lr, color='red', label='Predicted Fares (LR)')
plt.xlabel('Distance')
plt.ylabel('Fare Amount')
plt.title('Best Fit Line - Linear Regression')
plt.legend()
plt.show()



# In[13]:


# Step 9: Plotting the best fit line for Linear Regression
plt.figure(figsize=(8, 5))
plt.scatter(X_test['distance'], y_test, color='blue', label='Actual Fares')
plt.plot(X_test['distance'], y_pred_rf, color='red', label='Predicted Fares (LR)')
plt.xlabel('Distance')
plt.ylabel('Fare Amount')
plt.title('Best Fit Line - Linear Regression')
plt.legend()
plt.show()


# In[5]:


# Step 10: Make predictions on the entire dataset and add a new column for predicted fares
df['predicted_fare'] = rf_reg.predict(df[features])

# Display the first 10 rows of the updated dataset with the predictions
print("\nDataset with Predictions:")
print(df[['distance', 'hour', 'day', 'month', 'year', 'fare_amount', 'predicted_fare']].head(50))


# In[7]:


import pandas as pd
import numpy as np

def predict_fare(model):
    """Predict fare based on user input for all 5 features."""
    # Collect user input for all features
    distance = float(input("Enter the distance in km: "))
    hour = int(input("Enter the hour (0-23): "))
    day = int(input("Enter the day of the month (1-31): "))
    month = int(input("Enter the month (1-12): "))
    year = int(input("Enter the year (e.g., 2024): "))
    
    # Prepare the input data as a DataFrame with the correct feature names
    input_data = pd.DataFrame([[distance, hour, day, month, year]], 
                              columns=['distance', 'hour', 'day', 'month', 'year'])
    
    # Predict the fare using the model
    predicted_fare = model.predict(input_data)[0]
    
    print(f"\nPredicted fare for the given inputs is: ${predicted_fare:.2f}")
    return predicted_fare

# Allow user interaction
if __name__ == "__main__":
    print("Fare Prediction using Linear Regression/ random forest Model")
    predict_fare(rf_reg)  # Pass the trained linear regression/  random forest  model
